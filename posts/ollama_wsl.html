<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><link rel="icon" href="/favicon.ico" data-next-head=""/><meta name="description" content="A blog about software engineering, cybersecurity, and other topics." data-next-head=""/><meta name="og:title" content="another next js blog" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><title data-next-head="">ollama on wsl</title><link rel="preload" href="/plausible-denial/_next/static/css/fe53a19777309f0b.css" as="style"/><link rel="stylesheet" href="/plausible-denial/_next/static/css/fe53a19777309f0b.css" data-n-g=""/><link rel="preload" href="/plausible-denial/_next/static/css/bad59674c2c4f598.css" as="style"/><link rel="stylesheet" href="/plausible-denial/_next/static/css/bad59674c2c4f598.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/plausible-denial/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/plausible-denial/_next/static/chunks/webpack-1d2146f2f87d0d61.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/framework-052b50cd3d4947f2.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/main-c679951d4d57c5fb.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/pages/_app-8b2b478b1c32f058.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/111-b6d228a460ce1844.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/853-cd8f1d40d2155ed5.js" defer=""></script><script src="/plausible-denial/_next/static/chunks/pages/posts/%5Bid%5D-97bd4f323a85864d.js" defer=""></script><script src="/plausible-denial/_next/static/_RyBiTdRE2O2-pNf5Y02t/_buildManifest.js" defer=""></script><script src="/plausible-denial/_next/static/_RyBiTdRE2O2-pNf5Y02t/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_container__FUycR"><header class="layout_header__SFlEE"><div class="layout_headerBorder__4fKYf"><div class="layout_headerBox__e2QEL"><h1 class="utils_heading2Xl__oxFoJ">Plausible Denial</h1></div></div><nav class="layout_nav__R8qNp"><ul><li class=""><a href="/plausible-denial">Blog</a></li><li class=""><a href="/plausible-denial/about">About</a></li><li class=""><a href="/plausible-denial/tags">Tags</a></li></ul></nav></header><main><article><h1 class="utils_headingXl__zlq1q">ollama on wsl</h1><div class="utils_lightText__B_gv3"><time dateTime="2025-01-15">January 15, 2025</time></div><div><p>Having recently upgraded to a laptop with a GPU, I want to run my typical setup of WSL and VScode with docker.</p>
<p>I have managed to</p>
<p>https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image</p>
<p>https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation</p>
<p>https://ollama.com/library?sort=newest</p>
<p>I did not have to configure much but I did edit the daemon in both the WSL section and the Daemon config section in docker desktop.</p>
<p>This is what has me a little confused, how does docker desktop interact with the WSL command for docker.</p>
<p>Never the less it all seems to fit together. Meaning I now can create little AI friends yay...</p>
<p>I wonder if I can get siri to enact a shortcut to ping my custom AI friend.</p>
<p>I have to create a service mesh between my little host in AWS and my laptop. since my laptop is only running when I am using it, plus the whole dynamic ip thing.</p>
<p>I'm thinking of the solution where:</p>
<div class="hl hl-txt"><pre id="MC41NDY2OTUy" style="--hl-line-number-gutter-factor: 2"><code tabindex="0"><span class="line"><span class="line-number" aria-hidden="true">1</span>-> "Hey Siri, Ask Jarvis ..."</span>
<span class="line"><span class="line-number" aria-hidden="true">2</span></span>
<span class="line"><span class="line-number" aria-hidden="true">3</span>-> siri runs shortcut "Ask Jarvis" and fills the prompt with the text ...</span>
<span class="line"><span class="line-number" aria-hidden="true">4</span></span>
<span class="line"><span class="line-number" aria-hidden="true">5</span>-> shortcut sends request to discovery.systemctl.uk</span>
<span class="line"><span class="line-number" aria-hidden="true">6</span></span>
<span class="line"><span class="line-number" aria-hidden="true">7</span>-> EC2 forwards request to connected fulfillment service</span>
<span class="line"><span class="line-number" aria-hidden="true">8</span></span>
<span class="line"><span class="line-number" aria-hidden="true">9</span>-> EC2 responds with the relevant response including service issues.</span>
<span class="line"><span class="line-number" aria-hidden="true">10</span></span>
<span class="line"><span class="line-number" aria-hidden="true">11</span>-> Siri reads shortcut reply</span>
</code></pre></div>
<p>This has deffo been done before. I need to think of some steps to take and plan out in more detail.</p></div></article></main><div class="layout_backToHome__D9QFr"><a href="/plausible-denial">‚Üê Back to home</a></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"ollama_wsl","contentHtml":"\u003cp\u003eHaving recently upgraded to a laptop with a GPU, I want to run my typical setup of WSL and VScode with docker.\u003c/p\u003e\n\u003cp\u003eI have managed to\u003c/p\u003e\n\u003cp\u003ehttps://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image\u003c/p\u003e\n\u003cp\u003ehttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation\u003c/p\u003e\n\u003cp\u003ehttps://ollama.com/library?sort=newest\u003c/p\u003e\n\u003cp\u003eI did not have to configure much but I did edit the daemon in both the WSL section and the Daemon config section in docker desktop.\u003c/p\u003e\n\u003cp\u003eThis is what has me a little confused, how does docker desktop interact with the WSL command for docker.\u003c/p\u003e\n\u003cp\u003eNever the less it all seems to fit together. Meaning I now can create little AI friends yay...\u003c/p\u003e\n\u003cp\u003eI wonder if I can get siri to enact a shortcut to ping my custom AI friend.\u003c/p\u003e\n\u003cp\u003eI have to create a service mesh between my little host in AWS and my laptop. since my laptop is only running when I am using it, plus the whole dynamic ip thing.\u003c/p\u003e\n\u003cp\u003eI'm thinking of the solution where:\u003c/p\u003e\n\u003cdiv class=\"hl hl-txt\"\u003e\u003cpre id=\"MC41NDY2OTUy\" style=\"--hl-line-number-gutter-factor: 2\"\u003e\u003ccode tabindex=\"0\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e1\u003c/span\u003e-\u003e \"Hey Siri, Ask Jarvis ...\"\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e2\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e3\u003c/span\u003e-\u003e siri runs shortcut \"Ask Jarvis\" and fills the prompt with the text ...\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e4\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e5\u003c/span\u003e-\u003e shortcut sends request to discovery.systemctl.uk\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e6\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e7\u003c/span\u003e-\u003e EC2 forwards request to connected fulfillment service\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e8\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e9\u003c/span\u003e-\u003e EC2 responds with the relevant response including service issues.\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e10\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"line\"\u003e\u003cspan class=\"line-number\" aria-hidden=\"true\"\u003e11\u003c/span\u003e-\u003e Siri reads shortcut reply\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis has deffo been done before. I need to think of some steps to take and plan out in more detail.\u003c/p\u003e","title":"ollama on wsl","date":"2025-01-15","tags":"engineering, llm, ai"}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"ollama_wsl"},"buildId":"_RyBiTdRE2O2-pNf5Y02t","assetPrefix":"/plausible-denial","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>