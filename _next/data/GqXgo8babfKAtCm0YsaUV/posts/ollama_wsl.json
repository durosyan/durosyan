{"pageProps":{"postData":{"id":"ollama_wsl","contentHtml":"<p>Having recently upgraded to a laptop with a GPU, I want to run my typical setup of WSL and VScode with docker.</p>\n<p>I have managed to</p>\n<p>https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image</p>\n<p>https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation</p>\n<p>https://ollama.com/library?sort=newest</p>\n<p>I did not have to configure much but I did edit the daemon in both the WSL section and the Daemon config section in docker desktop.</p>\n<p>This is what has me a little confused, how does docker desktop interact with the WSL command for docker.</p>\n<p>Never the less it all seems to fit together. Meaning I now can create little AI friends yay...</p>\n<p>I wonder if I can get siri to enact a shortcut to ping my custom AI friend.</p>\n<p>I have to create a service mesh between my little host in AWS and my laptop. since my laptop is only running when I am using it, plus the whole dynamic ip thing.</p>\n<p>I'm thinking of the solution where:</p>\n<div class=\"hl hl-txt\"><pre id=\"MC41ODI1ODA4\" style=\"--hl-line-number-gutter-factor: 2\"><code tabindex=\"0\"><span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">1</span>-> \"Hey Siri, Ask Jarvis ...\"</span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">2</span></span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">3</span>-> siri runs shortcut \"Ask Jarvis\" and fills the prompt with the text ...</span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">4</span></span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">5</span>-> shortcut sends request to discovery.systemctl.uk</span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">6</span></span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">7</span>-> EC2 forwards request to connected fulfillment service</span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">8</span></span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">9</span>-> EC2 responds with the relevant response including service issues.</span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">10</span></span>\n<span class=\"line\"><span class=\"line-number\" aria-hidden=\"true\">11</span>-> Siri reads shortcut reply</span>\n</code></pre></div>\n<p>This has deffo been done before. I need to think of some steps to take and plan out in more detail.</p>","title":"ollama on wsl","date":"2025-01-15","tags":"engineering, llm, ai"}},"__N_SSG":true}